{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../src/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import _pickle as cPickle\n",
    "import argparse\n",
    "import data_generator as generator\n",
    "import model_codebase as cb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn.metrics as skmetrics \n",
    "\n",
    "from cicids2017_prophet import Cicids2017Preprocessor\n",
    "\n",
    "\n",
    "WINDOW_OVERLAPPING = .95\n",
    "FLEVEL = \"MAGIK\"\n",
    "CONTEXT_LEN = 80 # context window length, 28 minutes with 4spm (sample per minutes) \n",
    "ACTIVITY_LEN = 40 # activity window length, 14 minutes \n",
    "\n",
    "\n",
    "def prepare_dataset(datapath):\n",
    "    timeseries_data = datapath / \"CICIDS2017_ntop.pkl\"\n",
    "    df = pd.read_pickle(timeseries_data)\n",
    "    \n",
    "    pr = Cicids2017Preprocessor(flevel=FLEVEL, discretize=False)\n",
    "    \n",
    "    monday = 3\n",
    "    week_mask = df.index.get_level_values(\"_time\").day != monday\n",
    "    tserver_mask = df.index.get_level_values(\"host\") != \"192.168.10.50\"\n",
    "\n",
    "    training = df[week_mask & tserver_mask]\n",
    "    training = pr.preprocessing(training, fit=True)\n",
    "    normal_training_mask = (training[\"isanomaly\"] == \"none\")\n",
    "    training = training[normal_training_mask].drop(\"isanomaly\", axis=1)\n",
    "    training = training.reset_index().drop([\"device_category\", \"host\"], axis=1).rename(columns={\"_time\": \"ds\"})\n",
    "    \n",
    "    testing = df[np.bitwise_not(week_mask) & tserver_mask]\n",
    "    testing = pr.preprocessing(testing)\n",
    "    normal_testing_mask = (testing[\"isanomaly\"] == \"none\")\n",
    "    testing = testing[normal_testing_mask].drop(\"isanomaly\", axis=1)\n",
    "    testing = testing.reset_index().drop([\"device_category\", \"host\"], axis=1).rename(columns={\"_time\": \"ds\"})\n",
    "    \n",
    "    # Validation attacks: monday + week attacks\n",
    "    testing_attacks = df[np.bitwise_not(tserver_mask)]\n",
    "    testing_attacks = pr.preprocessing(testing_attacks)\n",
    "    testing_attacks = cb.ts_windowing(testing_attacks, overlapping=WINDOW_OVERLAPPING, context_len=CONTEXT_LEN)\n",
    " \n",
    "    datasets = { \"prophet_training\": training, \"prophet_testing\": testing,\n",
    "                 \"testing_attacks\": testing_attacks }\n",
    "    return datasets\n",
    "\n",
    "dd = prepare_dataset(Path(\"../dataset/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Prophet storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:fbprophet.plot:Importing plotly failed. Interactive plots will not work.\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "  5%|▌         | 1/19 [00:22<06:49, 22.74s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 11%|█         | 2/19 [00:34<05:31, 19.51s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 16%|█▌        | 3/19 [01:40<08:53, 33.35s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 21%|██        | 4/19 [01:40<05:51, 23.46s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 26%|██▋       | 5/19 [20:31<1:22:58, 355.58s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 32%|███▏      | 6/19 [22:11<1:00:26, 278.99s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 37%|███▋      | 7/19 [22:12<39:05, 195.43s/it]  INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 42%|████▏     | 8/19 [22:28<25:59, 141.78s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 47%|████▋     | 9/19 [23:38<20:03, 120.32s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 53%|█████▎    | 10/19 [23:53<13:16, 88.48s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 58%|█████▊    | 11/19 [24:13<09:04, 68.04s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 63%|██████▎   | 12/19 [24:13<05:34, 47.74s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 68%|██████▊   | 13/19 [24:51<04:28, 44.70s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 74%|███████▎  | 14/19 [26:22<04:53, 58.76s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 79%|███████▉  | 15/19 [27:52<04:32, 68.02s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 84%|████████▍ | 16/19 [28:04<02:33, 51.29s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 89%|████████▉ | 17/19 [28:54<01:41, 50.66s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      " 95%|█████████▍| 18/19 [29:09<00:40, 40.13s/it]INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "100%|██████████| 19/19 [48:18<00:00, 152.54s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from fbprophet import Prophet\n",
    "\n",
    "tr = dd[\"prophet_training\"]\n",
    "cols = set(tr.columns)\n",
    "cols.remove(\"ds\")\n",
    "P = defaultdict(lambda: Prophet(weekly_seasonality=True))\n",
    "\n",
    "for y in tqdm(cols):\n",
    "    other_cols = set(cols)\n",
    "    other_cols.remove(y)\n",
    "    ts = tr.rename(columns={y: \"y\"})\n",
    "    m = P[y]\n",
    "    for c in other_cols:\n",
    "        m.add_regressor(c)\n",
    "    m.fit(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing ANOMALY_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyscore(x: pd.DataFrame, verbose=True):\n",
    "    attribute_scores = []\n",
    "    iterator = tqdm(x.columns) if verbose else x.columns \n",
    "    \n",
    "    for c in iterator:\n",
    "        if c == \"ds\":\n",
    "            continue\n",
    "        \n",
    "        ground_truth = x[c]\n",
    "        model_input = x.drop(c, axis=1)\n",
    "        pred = P[c].predict(model_input)[[\"trend\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]].copy()\n",
    "        pred[\"ground_truth\"] = ground_truth\n",
    "\n",
    "        out_of_forchetta = ((pred[\"yhat\"] < pred[\"yhat_lower\"]) | (pred[\"yhat\"] > pred[\"yhat_upper\"]))\n",
    "        # Percentage of outliers in validation data for column 'c'\n",
    "        column_score = 1 - len(out_of_forchetta[out_of_forchetta==False]) / len(out_of_forchetta)\n",
    "        attribute_scores.append(column_score)\n",
    "        \n",
    "    return attribute_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:05<00:00, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set to: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = anomalyscore(dd[\"prophet_testing\"])\n",
    "ANOMALY_THRESHOLD = np.mean(s)\n",
    "print(f\"Threshold set to: {ANOMALY_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet attack prediction capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_columns = tr.columns[1:]\n",
    "\n",
    "def model_input_to_prophet(minput):\n",
    "    def gen_ctx_idx(start, end):\n",
    "        return list(map(lambda x: pd.Timestamp(x.mid, unit=\"s\"), pd.interval_range(st, en, 80)))\n",
    "    \n",
    "    zipped = zip(minput[\"context\"], minput[\"start_time\"], minput[\"end_time\"])\n",
    "    \n",
    "    res = []\n",
    "    for ctx, st, en in zipped:\n",
    "        ds = gen_ctx_idx(st, en)\n",
    "        df = pd.DataFrame(ctx, columns=ctx_columns)\n",
    "        df[\"ds\"] = ds\n",
    "        res.append(df)\n",
    "    return res\n",
    "        \n",
    "testing_attacks = dd[\"testing_attacks\"]\n",
    "prophet_testing_attacks = model_input_to_prophet(testing_attacks)\n",
    "y_attacks = testing_attacks[\"isanomaly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 2072/2087 [23:58:58<11:45, 47.05s/it]   "
     ]
    }
   ],
   "source": [
    "y_hat = []\n",
    "\n",
    "for ctx_ts in tqdm(prophet_testing_attacks):\n",
    "    ctx_score = anomalyscore(ctx_ts, verbose=False)\n",
    "    is_anomaly = np.mean(ctx_score) > ANOMALY_THRESHOLD\n",
    "    y_hat.append(is_anomaly)\n",
    "\n",
    "y_hat = np.array(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# report = metrics.classification_report(y_attacks, y_hat)\n",
    "metrics_rep = [ metrics.roc_auc_score,\n",
    "                metrics.precision_score, metrics.recall_score,\n",
    "                metrics.accuracy_score, metrics.f1_score]\n",
    "for m in metrics_rep:\n",
    "    mres = m(y_attacks, y_hat)\n",
    "    print(f\"{m.__name__}(moday+attacks): {mres}\")\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_attacks, y_hat, normalize=\"all\").ravel()\n",
    "print(\"\\n Confusion matrix\")\n",
    "print(f\"\\ttp: {tp} \\tfp: {fp} \\n\\tfn: {fn} \\ttn: {tn}\")\n",
    "print(f\"\\n{report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
