{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\n",
    "def replace_cname(df, oldname, newname):\n",
    "    new_names = { c: c.replace(oldname, newname).strip() for c in df.columns if oldname in c}\n",
    "    return df.rename(columns=new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = pd.DataFrame()\n",
    "\n",
    "RES_PATH = Path(f\"../res/\")\n",
    "files = [os.path.join(path, name) for path, subdirs, files in os.walk(RES_PATH) for name in files]\n",
    "grid_files = filter(lambda x: \"gridsearch\" in x, files)\n",
    "\n",
    "for f in grid_files:\n",
    "    if \"gridsearch\" not in f:\n",
    "        continue\n",
    "    df = pd.read_pickle(RES_PATH / f)\n",
    "    \n",
    "    additional_features = f.replace(\".pkl\", \"\").split(\"__\")[1:]\n",
    "    additional_features = map(lambda x: x.split(\"_\"), additional_features)\n",
    "    \n",
    "    for f, v in additional_features:\n",
    "        df[f\"param_{f}\"] = v\n",
    "        \n",
    "    grid_search = pd.concat([grid_search, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cols = [ c for c in grid_search.columns if \"param_\" in c ]\n",
    "grid_search = grid_search[features_cols + [\"mean_test_score\"]]\n",
    "\n",
    "grid_search = grid_search.rename(columns={\"param_module\": \"architecture\"})\n",
    "grid_search = replace_cname(grid_search, \"_\", \" \")\n",
    "grid_search = replace_cname(grid_search, \"param\", \"\")\n",
    "grid_search = replace_cname(grid_search, \"module\", \"\")\n",
    "\n",
    "best_results = grid_search.sort_values(\"mean test score\", ascending=True)\n",
    "best_results = best_results.groupby(\"pool\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_results = best_results.drop([\"input size\", \"feature set\", \"discretized\", \"architecture\", \"context len\", \"overlapping\"], axis=1)\n",
    "best_results = best_results[best_results[\"pool\"]==\"last\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllr}\n",
      "\\toprule\n",
      "batch size & lr & latent size & pool & rnn layers & rnn size & mean test score \\\\\n",
      "\\midrule\n",
      " 4096 & 0.0005 & 128 & last & 3 & 128 & 0.0820 \\\\\n",
      " 4096 & 0.0005 & 128 & last & 3 & 64 & 0.0822 \\\\\n",
      " 4096 & 0.0005 & 64 & last & 3 & 128 & 0.0841 \\\\\n",
      " 4096 & 0.0001 & 64 & last & 3 & 128 & 0.0849 \\\\\n",
      " 4096 & 0.0001 & 64 & last & 3 & 64 & 0.0852 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_str = best_results.head(5).to_latex(index=False, float_format=\"{:0.4f}\".format)\n",
    "print(re.sub(' +',' ', latex_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
